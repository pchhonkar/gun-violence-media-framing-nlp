# Task 4: Manual Cluster Evaluation and Refinement

## Overview

This document presents a qualitative evaluation of the clusters generated by DBSCAN in Task 3, followed by manual refinements to improve cluster interpretability and purity.

**Input files:**
- `outputs/processed/descriptions_with_clusters.csv`
- `outputs/processed/cluster_summary.csv`

**Output files:**
- `outputs/processed/cluster_refinement_map.json`
- `outputs/processed/descriptions_with_clusters_refined.csv`

---

# PART 1: SHOOTER CLUSTER EVALUATION

## Cluster: "Cluster 1: gunman" (Original)

**Size:** Large cluster (varies by run)

### Lexical Coherence
- **Rating:** Medium
- **Notes:** Phrases share common lexical items ("gunman", "shooter", "suspect") but vary significantly in modifiers and context.

### Semantic Coherence
- **Rating:** Low
- **Notes:** The cluster conflates multiple distinct framings:
  1. Simple identity labels ("the gunman", "the shooter")
  2. Legal/epistemic hedging ("alleged shooter", "suspected shooter")
  3. Threat status ("active shooter")
  4. Event references ("a shooting", "shooting incident")

### Cluster Purity
- **Rating:** Low
- **Notes:** Contains misclassified phrases that describe events rather than the shooter entity. Also contains malformed extractions ("old gunman grandmother", "gunman intentions").

### Decision: SPLIT into 4 refined clusters

---

## Cluster: "Noise/Unclustered" (Shooter, Original cluster_id=-1)

### Evaluation
Contains phrases that DBSCAN could not assign to any cluster due to low density. Some phrases are genuinely noise, but others may be valuable edge cases.

### Decision: KEEP as-is, but add malformed phrases from other clusters

---

# PART 2: VICTIM CLUSTER EVALUATION

## Cluster: "Age references" (Original)

**Size:** Medium-large cluster

### Lexical Coherence
- **Rating:** High
- **Notes:** Most phrases contain numeric age/count references or child-related terms.

### Semantic Coherence
- **Rating:** Medium
- **Notes:** The cluster mixes two distinct framings:
  1. Demographic counting ("19 children", "14 students")
  2. Harm descriptions involving children ("killed kids", "fatally shot children")

### Cluster Purity
- **Rating:** Medium
- **Notes:** All phrases relate to child victims, but the semantic function differs between counting/identification and harm description.

### Decision: SPLIT into 2 refined clusters

---

## Cluster: "Harm severity" (Original)

### Lexical Coherence
- **Rating:** High
- **Notes:** Phrases consistently contain harm-related vocabulary ("killed", "injured", "wounded", "dead").

### Semantic Coherence
- **Rating:** High
- **Notes:** Phrases uniformly describe harm outcomes.

### Cluster Purity
- **Rating:** High

### Decision: KEEP as-is

---

## Cluster: "Legal/process framing" (Original)

### Lexical Coherence
- **Rating:** High
- **Notes:** Contains legal terminology ("arrested", "charged", "custody").

### Semantic Coherence
- **Rating:** High

### Cluster Purity
- **Rating:** High

### Decision: KEEP as-is

---

# PART 3: REFINEMENT SPECIFICATIONS

## Shooter Cluster Refinements

### Original: "Cluster 1: gunman" → SPLIT INTO:

#### 1. "Shooter identity labels"
Phrases that provide simple identity reference to the shooter without epistemic hedging or status information.

**Inclusion criteria:**
- Simple noun phrases: "a gunman", "the gunman", "the shooter", "the suspect"
- No modifiers suggesting uncertainty or legal status

**Example phrases:**
- a gunman
- the gunman
- the shooter
- the suspect
- gunman
- shooter

#### 2. "Alleged/suspected shooter framing"
Phrases with epistemic hedging indicating uncertainty about shooter identity.

**Inclusion criteria:**
- Contains "alleged", "suspected", "accused", or similar hedging terms

**Example phrases:**
- alleged shooter
- suspected shooter
- the alleged shooter
- the suspected gunman
- accused shooter

#### 3. "Active threat framing"
Phrases describing the shooter as an active/ongoing threat.

**Inclusion criteria:**
- Contains "active shooter" or similar threat-status terminology

**Example phrases:**
- active shooter
- "active shooter"
- an active shooter

#### 4. "Event/incident framing" → Reassign to Noise
Phrases that describe the event rather than the shooter entity.

**Inclusion criteria:**
- Describes "a shooting" or "shooting incident" without entity reference

**Example phrases:**
- a shooting
- a shooting incident
- the shooting
- shooting incident

#### 5. Malformed phrases → Reassign to "Noise/Unclustered"

**Example phrases:**
- old gunman grandmother
- gunman intentions
- gunman grandmother
- gunman who

---

## Victim Cluster Refinements

### Original: "Age references" → SPLIT INTO:

#### 1. "Victim age & count framing"
Phrases that quantify or count victims, often with age/demographic information.

**Inclusion criteria:**
- Contains numeric counts ("19", "14", "at least")
- Describes quantity of victims without explicit harm verbs

**Example phrases:**
- 19 children
- 14 students
- at least 18 students
- eight students
- two teachers
- 21 people

#### 2. "Child victim harm framing"
Phrases that describe harm actions directed at child victims.

**Inclusion criteria:**
- Contains harm verbs ("killed", "shot", "killing") combined with child references

**Example phrases:**
- killed kids
- fatally shot children
- killing children
- left children
- shot children
- murdered children

---

# PART 4: JUSTIFICATION

## Why DBSCAN Merged These Clusters

DBSCAN clusters based on embedding similarity in dense regions. The merged clusters share:

1. **Lexical overlap:** "gunman", "shooter", "children" appear across semantically distinct phrases
2. **Embedding proximity:** Sentence-BERT embeds phrases with shared vocabulary close together
3. **Density requirements:** Small semantic distinctions don't create separate density peaks

## How Manual Refinement Improves Interpretability

1. **Semantic precision:** Splits separate distinct framings (identity vs. hedging vs. threat status)
2. **Analytical utility:** Refined clusters enable more meaningful cross-outlet comparisons
3. **Noise reduction:** Malformed phrases removed from meaningful clusters
4. **Frame analysis:** Clearer mapping to media framing categories (epistemic hedging, harm emphasis, etc.)

---

# PART 5: BEFORE VS AFTER COMPARISON

## Shooter Clusters

| Before | After |
|--------|-------|
| Cluster 1: gunman (mixed) | Shooter identity labels |
| | Alleged/suspected shooter framing |
| | Active threat framing |
| | (Event phrases → Noise) |
| Noise/Unclustered | Noise/Unclustered (expanded) |

## Victim Clusters

| Before | After |
|--------|-------|
| Age references (mixed) | Victim age & count framing |
| | Child victim harm framing |
| Harm severity | Harm severity (unchanged) |
| Legal/process framing | Legal/process framing (unchanged) |

---

# PART 6: IMPLEMENTATION NOTES

The refinements are applied programmatically via:
1. `outputs/processed/cluster_refinement_map.json` - Phrase-to-cluster mapping
2. `src/manual_eval_helpers.py` - `apply_refinement_map()` function
3. Output: `outputs/processed/descriptions_with_clusters_refined.csv`

The original clustering file (`descriptions_with_clusters.csv`) is preserved unchanged.

---

## References

- Task 3 clustering used DBSCAN with cosine distance on Sentence-BERT embeddings
- Refinement criteria based on media framing literature and lexical analysis
- No re-embedding or re-clustering performed; refinements are post-hoc label adjustments

